{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2ca4f2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "    <h1> Tutorial 3 </h1> \n",
    "    <h2> Random Forests </h2>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb5b52",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceefc5e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "\n",
    "<h1>Random Forests </h1>\n",
    "\n",
    "\n",
    " \n",
    "## The very basics\n",
    "   \n",
    "    \n",
    "## Recommended reading \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120aedf",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "    \n",
    "<h1> Machine Learning Theory </h1>\n",
    "<a href=\"\">\n",
    "<img src=\"\">\n",
    "</a>\n",
    "\n",
    "    \n",
    "## Random Forests\n",
    "\n",
    "  \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d6637",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "<h1> Python </h1>\n",
    "\n",
    "Basic python knowledge is assumed for this tutorial. \n",
    " \n",
    "    \n",
    "## Keras\n",
    "    \n",
    "</div>\n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696361fc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffffcc; padding: 10px;\">\n",
    "    \n",
    "<h1> Requirements </h1>\n",
    "\n",
    "These notebooks should run with the following requirements satisfied\n",
    "\n",
    "<h2> Python Packages: </h2>\n",
    "\n",
    "* Python 3\n",
    "* tensorflow\n",
    "\n",
    "\n",
    "<h2> Data Requirements</h2>\n",
    "    \n",
    "This notebook referes to some data included in the git hub repositroy\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb015f28",
   "metadata": {},
   "source": [
    "\n",
    "**Contents:**\n",
    "\n",
    "\n",
    "1. [Leaf Data](#Leaf-Data)\n",
    "2. [Decision Trees](#Decision-Trees)\n",
    "3. [Random Forests](#Random-Forests)\n",
    "4. [K fold cross validation](#K-fold-cross-validation)\n",
    "4. [HyperParameters](#HyperParameters)\n",
    "5. [Train Random Forest](#Train-Random-Forest)\n",
    "6. [Results](#Results) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5fa5cb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "Load in all required modules (includig some auxillary code) and turn off warnings. Make sure Keras session is clear\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f8a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For readability: disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ad690",
   "metadata": {},
   "source": [
    "# Leaf Data\n",
    "\n",
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "\n",
    "Observational data 805 obs of bean leaves multispec device measures\n",
    "\n",
    "| Feature |\n",
    "| ------- |\n",
    "| air temp |\n",
    "|IR temp leaf temp |\n",
    "|RH |\n",
    "| Photosyntheticakky activate radtion (usable light)|\n",
    "| Photo efficency |\n",
    "| leaf health (greeness relative chorophyll) |\n",
    "| proton conductivity |\n",
    "| leaf thickness |\n",
    "| leaf angle |   \n",
    "\n",
    "These feauture are chosen from scientific theory \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17740d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6c1cc8d00223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Set random seed to ensure \"reproducible\" runs\n",
    "RSEED = 50\n",
    "# Load in Data\n",
    "X = np.array([[2, 2], \n",
    "              [2, 1],\n",
    "              [2, 3], \n",
    "              [1, 2], \n",
    "              [1, 1],\n",
    "              [3, 3]])\n",
    "# Dummy array e.g. precip\n",
    "y = np.array([0, 1, 1, 1, 0, 1])\n",
    "# Clean Data\n",
    "# Plot data?\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.figure(figsize = (8, 8))\n",
    "\n",
    "# Plot each point as the label\n",
    "for x1, x2, label in zip(X[:, 0], X[:, 1], y):\n",
    "    plt.text(x1, x2, str(label), fontsize = 40, color = 'g',\n",
    "             ha='center', va='center')\n",
    "    \n",
    "# Plot formatting\n",
    "plt.grid(None);\n",
    "plt.xlim((0, 3.5));\n",
    "plt.ylim((0, 3.5));\n",
    "plt.xlabel('leaf temp', size = 20); plt.ylabel('air temp', size = 20); plt.title('Precip', size = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5b943",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "<div style=\"background-color: #e6ccff; padding: 10px;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63657709",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ccffcc; padding: 10px;\">\n",
    "Leaf stuff...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a decision tree and train\n",
    "tree = DecisionTreeClassifier(random_state=RSEED)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58caf139",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #cce5ff; padding: 10px;\">\n",
    "\n",
    "<h1> Visualizing and </h1>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaaadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')\n",
    "print(f'Model Accuracy: {tree.score(X, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bdf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulalizing the tree\n",
    "\n",
    "# Export as dot\n",
    "export_graphviz(tree, 'tree.dot', rounded = True, \n",
    "                feature_names = ['sst', 'time'], \n",
    "                class_names = ['0', '1'], filled = True)\n",
    "# Convert to png make the graphziv a png image\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'example_tree.png', '-Gdpi=400']);\n",
    "Image('example_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0b025",
   "metadata": {},
   "source": [
    "At each node the decision tree considers a feature based question reducing the Gini impurity, using the samples with values (no samples in class 1 and class 2 (0,1 here) to predict the class (0 or 1)\n",
    "\n",
    "### Gini Impurity \n",
    "\n",
    "The probability  that a randomly selected sample from a node will be incorrectly classified according to the distribution of samples in a node. At each split the tree tries to pick values that reduce the gini impurity, here we get to 0 for every training point as no limit was set \n",
    "\n",
    "bias- variance trade off, the model is \"less accurate\" but would perform much better on non training data than the overfitted model...\n",
    "\n",
    "**random forests** - we could also make lots of trees of subsets of the data and take an average\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Example with a real dataset\n",
    "\n",
    "real data downloaded from [Kaggle](https://www.kaggle.com/cdc/behavioral-risk-factor-surveillance-system), of 100,000 induviduals with features for socioeconomic and lifestyle indicators to predict overall health (0, 1) (poor, good)\n",
    "\n",
    "data is imbalanced so accuracy is not so useful use:\n",
    "\n",
    "* recall\n",
    "* precision\n",
    "* reciever operating charateristic area under curve (ROC AUC)\n",
    "\n",
    "## Training\n",
    "\n",
    "* 70% : 30% split training testing \n",
    "* can use sklearn to split the data\n",
    "* must make sure no missing values (imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99867b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the labels\n",
    "labels = np.array(df.pop('label'))\n",
    "\n",
    "# 30% examples in test data\n",
    "train, test, train_labels, test_labels = train_test_split(df, labels, \n",
    "                                                          stratify = labels,\n",
    "                                                          test_size = 0.3, \n",
    "                                                          random_state = RSEED)\n",
    "# fill in missing values\n",
    "train = train.fillna(train.mean())\n",
    "test = test.fillna(test.mean())\n",
    "\n",
    "# Features for feature importances\n",
    "features = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train tree\n",
    "tree.fit(train, train_labels)\n",
    "print(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb53a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will over fit\n",
    "# Make probability predictions\n",
    "train_probs = tree.predict_proba(train)[:, 1]\n",
    "probs = tree.predict_proba(test)[:, 1]\n",
    "\n",
    "train_predictions = tree.predict(train)\n",
    "predictions = tree.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(train_labels, train_probs)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(test_labels, probs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423de32",
   "metadata": {},
   "source": [
    "Visualising predictions vs truth - many false negatives and positives\n",
    "\n",
    "<hr> \n",
    "\n",
    "## feature importance\n",
    "\n",
    "The good things about these trees is we can detect what the important features were in the decision tree by summoning the Gini Impurity over all the nodes of the tree in which the features are used. e.g here \"DIFFWALK\" was highly important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree as dot file\n",
    "export_graphviz(tree, 'tree_real_data.dot', rounded = True, \n",
    "                feature_names = features, max_depth = 6,\n",
    "                class_names = ['poor health', 'good health'], filled = True)\n",
    "\n",
    "# Convert to png\n",
    "call(['dot', '-Tpng', 'tree_real_data.dot', '-o', 'tree_real_data.png', '-Gdpi=200'])\n",
    "\n",
    "# Visualize\n",
    "Image(filename='tree_real_data.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree as dot file\n",
    "export_graphviz(tree, 'tree_real_data.dot', rounded = True, \n",
    "                feature_names = features, max_depth = 6,\n",
    "                class_names = ['poor health', 'good health'], filled = True)\n",
    "\n",
    "# Convert to png\n",
    "call(['dot', '-Tpng', 'tree_real_data.dot', '-o', 'tree_real_data.png', '-Gdpi=200'])\n",
    "\n",
    "# Visualize\n",
    "Image(filename='tree_real_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06894296",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "basically an ensemble (1000 or 100,000 s) of decision trees, training each tree on a random set of observations and for each node only a subset of features are used and the predictions are averaged to arrive at he final classifciation\n",
    "\n",
    "### scikit-learn example\n",
    "\n",
    "1. 100 trees theat are very deep - each tree will over fit but the forest will not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b3b96",
   "metadata": {},
   "source": [
    "## K fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c62a3",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7487e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
